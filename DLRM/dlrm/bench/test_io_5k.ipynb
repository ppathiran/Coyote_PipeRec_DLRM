{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 45840617\n",
      "Count the number of rows: 6.764153292999254 s\n"
     ]
    }
   ],
   "source": [
    "#! Count the numer of rows\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "datafile = '/local/home/yuzhuyu/train.txt'\n",
    "days = 1\n",
    "total_count = 0\n",
    "total_per_file = []\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "with open(str(datafile)) as f:\n",
    "    for _ in f:\n",
    "        total_count += 1\n",
    "total_per_file.append(total_count)\n",
    "# reset total per file due to split\n",
    "num_data_per_split, extras = divmod(total_count, days)\n",
    "total_per_file = [num_data_per_split] * days\n",
    "for j in range(extras):\n",
    "    total_per_file[j] += 1\n",
    "# split into days (simplifies code later on)\n",
    "file_id = 0\n",
    "boundary = total_per_file[file_id]\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Number of rows: {total_count}\")\n",
    "print(f\"Count the number of rows: {t1-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 45840617\n",
      "Count the number of rows: 20.389811540000665 s\n"
     ]
    }
   ],
   "source": [
    "# Read data into array\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "datafile = '/local/home/yuzhuyu/train.txt'\n",
    "days = 1\n",
    "total_count = 0\n",
    "total_per_file = []\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "with open(str(datafile)) as f:\n",
    "    for _ in f:\n",
    "        total_count += 1\n",
    "total_per_file.append(total_count)\n",
    "# reset total per file due to split\n",
    "num_data_per_split, extras = divmod(total_count, days)\n",
    "total_per_file = [num_data_per_split] * days\n",
    "for j in range(extras):\n",
    "    total_per_file[j] += 1\n",
    "# split into days (simplifies code later on)\n",
    "\n",
    "file_id = 0\n",
    "boundary = total_per_file[file_id]\n",
    "\n",
    "sif_output = [[] for _ in range(days)]\n",
    "current_file_data = sif_output[file_id]\n",
    "with open(str(datafile)) as f:\n",
    "    for j, line in enumerate(f):\n",
    "        if j == boundary:\n",
    "            file_id += 1\n",
    "            # MODIFIED: Switch to the next inner list for the new \"file\" or split of data.\n",
    "            current_file_data = sif_output[file_id]\n",
    "            boundary += total_per_file[file_id]\n",
    "        # MODIFIED: Append line to the in-memory data structure instead of writing to a file.\n",
    "        current_file_data.append(line)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Number of rows: {total_count}\")\n",
    "print(f\"Count the number of rows: {t1-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count the number of rows: 20.36761131899948 s\n",
      "Split input: 31.94603248599924 s\n",
      "Total: 52.31364380499872 s\n"
     ]
    }
   ],
   "source": [
    "#! Split input\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "datafile = '/local/home/yuzhuyu/train.txt'\n",
    "days = 1\n",
    "max_ind_range = 5000\n",
    "total_count = 0\n",
    "total_per_file = []\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "with open(str(datafile)) as f:\n",
    "    for _ in f:\n",
    "        total_count += 1\n",
    "total_per_file.append(total_count)\n",
    "# reset total per file due to split\n",
    "num_data_per_split, extras = divmod(total_count, days)\n",
    "total_per_file = [num_data_per_split] * days\n",
    "for j in range(extras):\n",
    "    total_per_file[j] += 1\n",
    "# split into days (simplifies code later on)\n",
    "\n",
    "file_id = 0\n",
    "boundary = total_per_file[file_id]\n",
    "\n",
    "sif_output = [[] for _ in range(days)]\n",
    "current_file_data = sif_output[file_id]\n",
    "with open(str(datafile)) as f:\n",
    "    for j, line in enumerate(f):\n",
    "        if j == boundary:\n",
    "            file_id += 1\n",
    "            # MODIFIED: Switch to the next inner list for the new \"file\" or split of data.\n",
    "            current_file_data = sif_output[file_id]\n",
    "            boundary += total_per_file[file_id]\n",
    "        # MODIFIED: Append line to the in-memory data structure instead of writing to a file.\n",
    "        current_file_data.append(line)\n",
    "\n",
    "\n",
    "\n",
    "data_input = sif_output[0]\n",
    "num_data_in_split = total_per_file[0]\n",
    "data_output = []\n",
    "\n",
    "y = np.zeros(num_data_in_split, dtype=\"i4\") \n",
    "X_int = np.zeros((num_data_in_split, 13), dtype=\"i4\")\n",
    "X_cat = np.zeros((num_data_in_split, 26), dtype=\"i4\") \n",
    "\n",
    "i = 0\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "for k, line in enumerate(data_input):\n",
    "    # split \n",
    "    line = line.split(\"\\t\")\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Count the number of rows: {t1-t0} s\")\n",
    "print(f\"Split input: {t2-t1} s\")\n",
    "print(f\"Total: {t2-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count the number of rows: 22.029834287000995 s\n",
      "Fill missing values: 183.56466146599996 s\n",
      "Total: 205.59449575300096 s\n"
     ]
    }
   ],
   "source": [
    "#! Fill missing values\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "datafile = '/local/home/yuzhuyu/train.txt'\n",
    "days = 1\n",
    "max_ind_range = 5000\n",
    "total_count = 0\n",
    "total_per_file = []\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "with open(str(datafile)) as f:\n",
    "    for _ in f:\n",
    "        total_count += 1\n",
    "total_per_file.append(total_count)\n",
    "# reset total per file due to split\n",
    "num_data_per_split, extras = divmod(total_count, days)\n",
    "total_per_file = [num_data_per_split] * days\n",
    "for j in range(extras):\n",
    "    total_per_file[j] += 1\n",
    "# split into days (simplifies code later on)\n",
    "\n",
    "file_id = 0\n",
    "boundary = total_per_file[file_id]\n",
    "\n",
    "sif_output = [[] for _ in range(days)]\n",
    "current_file_data = sif_output[file_id]\n",
    "with open(str(datafile)) as f:\n",
    "    for j, line in enumerate(f):\n",
    "        if j == boundary:\n",
    "            file_id += 1\n",
    "            # MODIFIED: Switch to the next inner list for the new \"file\" or split of data.\n",
    "            current_file_data = sif_output[file_id]\n",
    "            boundary += total_per_file[file_id]\n",
    "        # MODIFIED: Append line to the in-memory data structure instead of writing to a file.\n",
    "        current_file_data.append(line)\n",
    "\n",
    "\n",
    "\n",
    "data_input = sif_output[0]\n",
    "num_data_in_split = total_per_file[0]\n",
    "data_output = []\n",
    "\n",
    "y = np.zeros(num_data_in_split, dtype=\"i4\") \n",
    "X_int = np.zeros((num_data_in_split, 13), dtype=\"i4\")\n",
    "X_cat = np.zeros((num_data_in_split, 26), dtype=\"i4\") \n",
    "\n",
    "i = 0\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "for k, line in enumerate(data_input):\n",
    "    # split \n",
    "    line = line.split(\"\\t\")\n",
    "    # fill missing vlaue\n",
    "    for j in range(len(line)):\n",
    "        if (line[j] == \"\") or (line[j] == \"\\n\"):\n",
    "            line[j] = \"0\"\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Count the number of rows: {t1-t0} s\")\n",
    "print(f\"Fill missing values: {t2-t1} s\")\n",
    "print(f\"Total: {t2-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count the number of rows: 21.08693008999944 s\n",
      "Full decoding 5000: 653.7508090430001 s\n",
      "Total: 674.8377391329996 s\n"
     ]
    }
   ],
   "source": [
    "#! Hex2Int & Modulus & Full Decoding\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "datafile = '/local/home/yuzhuyu/train.txt'\n",
    "#! Read data into array\n",
    "days = 1\n",
    "max_ind_range = 5000\n",
    "total_count = 0\n",
    "total_per_file = []\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "with open(str(datafile)) as f:\n",
    "    for _ in f:\n",
    "        total_count += 1\n",
    "total_per_file.append(total_count)\n",
    "# reset total per file due to split\n",
    "num_data_per_split, extras = divmod(total_count, days)\n",
    "total_per_file = [num_data_per_split] * days\n",
    "for j in range(extras):\n",
    "    total_per_file[j] += 1\n",
    "# split into days (simplifies code later on)\n",
    "\n",
    "file_id = 0\n",
    "boundary = total_per_file[file_id]\n",
    "\n",
    "sif_output = [[] for _ in range(days)]\n",
    "current_file_data = sif_output[file_id]\n",
    "with open(str(datafile)) as f:\n",
    "    for j, line in enumerate(f):\n",
    "        if j == boundary:\n",
    "            file_id += 1\n",
    "            # MODIFIED: Switch to the next inner list for the new \"file\" or split of data.\n",
    "            current_file_data = sif_output[file_id]\n",
    "            boundary += total_per_file[file_id]\n",
    "        # MODIFIED: Append line to the in-memory data structure instead of writing to a file.\n",
    "        current_file_data.append(line)\n",
    "\n",
    "\n",
    "\n",
    "data_input = sif_output[0]\n",
    "num_data_in_split = total_per_file[0]\n",
    "data_output = []\n",
    "\n",
    "y = np.zeros(num_data_in_split, dtype=\"i4\") \n",
    "X_int = np.zeros((num_data_in_split, 13), dtype=\"i4\")\n",
    "X_cat = np.zeros((num_data_in_split, 26), dtype=\"i4\") \n",
    "\n",
    "i = 0\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "for k, line in enumerate(data_input):\n",
    "    # split \n",
    "    line = line.split(\"\\t\")\n",
    "    # fill missing vlaue\n",
    "    for j in range(len(line)):\n",
    "        if (line[j] == \"\") or (line[j] == \"\\n\"):\n",
    "            line[j] = \"0\"\n",
    "\n",
    "    # data_output.append(split_line)\n",
    "    target = np.int32(line[0])\n",
    "\n",
    "    y[i] = target\n",
    "    X_int[i] = np.array(line[1:14], dtype=np.int32)\n",
    "    if max_ind_range > 0:\n",
    "        X_cat[i] = np.array(\n",
    "            list(map(lambda x: int(x, 16) % max_ind_range, line[14:])),\n",
    "            dtype=np.int32,\n",
    "        )\n",
    "    else:\n",
    "        X_cat[i] = np.array(\n",
    "            list(map(lambda x: int(x, 16), line[14:])), dtype=np.int32\n",
    "        )\n",
    "    i += 1\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Count the number of rows: {t1-t0} s\")\n",
    "print(f\"Full decoding 5000: {t2-t1} s\")\n",
    "print(f\"Total: {t2-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45840617, 26)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract uniques: 362.4644642530002 s\n",
      "Map index to unique features: 0.006725986000674311 s\n",
      "Total: 362.47119023900086 s\n"
     ]
    }
   ],
   "source": [
    "#! Count uniques 5000\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "i = 0\n",
    "convertDicts = [{} for _ in range(26)]\n",
    "\n",
    "for i in range(total_count):\n",
    "    for j in range(26):\n",
    "        convertDicts[j][X_cat[i][j]] = 1\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "for j in range(26):\n",
    "    for i, x in enumerate(convertDicts[j]):\n",
    "        convertDicts[j][x] = i\n",
    "\n",
    "t2 = time.perf_counter()       \n",
    "\n",
    "print(f\"Extract uniques: {t1-t0} s\")\n",
    "print(f\"Map index to unique features: {t2-t1} s\")\n",
    "print(f\"Total: {t2-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 332.269353063999 s\n"
     ]
    }
   ],
   "source": [
    "#! ApplyVocab - Map\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "i = total_count\n",
    "\n",
    "data = {\n",
    "    'X_int': X_int[0:i, :],\n",
    "    # 'X_cat': X_cat[0:i, :],\n",
    "    'X_cat_t': np.transpose(X_cat[0:i, :]),  # transpose of the data\n",
    "    'y': y[0:i],\n",
    "}\n",
    "\n",
    "X_cat_t = np.zeros(data[\"X_cat_t\"].shape)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "for j in range(26):\n",
    "    for k, x in enumerate(data[\"X_cat_t\"][j, :]):\n",
    "        X_cat_t[j, k] = convertDicts[j][x]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "     \n",
    "print(f\"Total: {t1-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply: 348.4950387460012 s\n",
      "Neg 2 Zero: 0.15816942299716175 s\n",
      "Logarithm: 1.3129091060000064 s\n",
      "Total: 349.9661172749984 s\n"
     ]
    }
   ],
   "source": [
    "#! Logarithm\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "data = {\n",
    "    'X_int': X_int[0:i, :],\n",
    "    # 'X_cat': X_cat[0:i, :],\n",
    "    'X_cat_t': np.transpose(X_cat[0:i, :]),  # transpose of the data\n",
    "    'y': y[0:i],\n",
    "}\n",
    "\n",
    "X_cat_t = np.zeros(data[\"X_cat_t\"].shape)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "for j in range(26):\n",
    "    for k, x in enumerate(data[\"X_cat_t\"][j, :]):\n",
    "        X_cat_t[j, k] = convertDicts[j][x]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "X_int_c = data[\"X_int\"]\n",
    "X_int_c[X_int_c < 0] = 0\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "X_int_c = np.log(X_int_c.astype(np.float32) + 1)\n",
    "t3 = time.perf_counter()\n",
    "     \n",
    "print(f\"Apply: {t1-t0} s\")\n",
    "print(f\"Neg 2 Zero: {t2-t1} s\")\n",
    "print(f\"Logarithm: {t3-t2} s\")\n",
    "print(f\"Total: {t3-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary dataset has the size of 8801398464\n",
      "The binary dataset contains 45840617 rows.\n",
      "Initialize: 0.0006437839983846061 s\n",
      "Read into array: 14.294507573002193 s\n",
      "Struct unpack: 36.494236826001725 s\n",
      "Total: 50.7893881830023 s\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "datafile = '/local/home/yuzhuyu/processed_data.bin'\n",
    "\n",
    "num_integers = 48\n",
    "integer_size = 4  # Size of one integer in bytes (4 bytes for 32-bit integer)\n",
    "row_size = num_integers * integer_size  # Total size of a row in bytes\n",
    "\n",
    "file_size = path.getsize(datafile)\n",
    "print(f\"The binary dataset has the size of {file_size}\")\n",
    "total_count = file_size // row_size\n",
    "print(f\"The binary dataset contains {total_count} rows.\")\n",
    "#! MODIFIED FINISH\n",
    "total_per_file.append(total_count)\n",
    "# reset total per file due to split\n",
    "num_data_per_split, extras = divmod(total_count, days)\n",
    "total_per_file = [num_data_per_split] * days\n",
    "for j in range(extras):\n",
    "    total_per_file[j] += 1\n",
    "# split into days (simplifies code later on)\n",
    "file_id = 0\n",
    "boundary = total_per_file[file_id]\n",
    "\n",
    "sif_output = [[] for _ in range(days)]\n",
    "current_file_data = sif_output[file_id]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "with open(datafile, 'rb') as f:  # Open the file in binary read mode.\n",
    "    j = 0\n",
    "    while j < total_count:  # Continue to loop until the end of the file.\n",
    "        binary_row = f.read(row_size)  # Read one row of binary data.\n",
    "        if not binary_row:  # If no data was read, end of file was reached.\n",
    "            break\n",
    "        if len(binary_row) != row_size:\n",
    "            print(\"Incomplete row of data encountered. Possible file corruption or unexpected end of file.\")\n",
    "            break\n",
    "        # print(integers)  # Print the tuple of integers.\n",
    "        if j == boundary:\n",
    "            file_id += 1\n",
    "            # MODIFIED: Switch to the next inner list for the new \"file\" or split of data.\n",
    "            current_file_data = sif_output[file_id]\n",
    "            boundary += total_per_file[file_id]\n",
    "\n",
    "        # MODIFIED: Append line to the in-memory data structure instead of writing to a file.\n",
    "        current_file_data.append(binary_row)\n",
    "        j += 1\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "data_input = sif_output[0]\n",
    "for k, binary_row in enumerate(data_input):\n",
    "    format_string = f'<{num_integers}I'  \n",
    "    line = struct.unpack(format_string, binary_row) \n",
    "\n",
    "t3 = time.perf_counter()\n",
    "\n",
    "print(f\"Initialize: {t1-t0} s\")\n",
    "print(f\"Read into array: {t2-t1} s\")\n",
    "print(f\"Struct unpack: {t3-t2} s\")\n",
    "print(f\"Total: {t3-t0} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
